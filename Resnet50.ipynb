{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ETSlime/GoogleColab/blob/Advance-Vision/Resnet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehHSOUQzlZVp",
        "outputId": "e2a6a9aa-d215-4aba-f50f-feba2485e0b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "GPU 0: Tesla K80 (UUID: GPU-a9c4a19d-985d-7150-f26e-a374db91c613)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tUAFf8oi6Ad",
        "outputId": "897ccfae-f1bc-4904-dcb9-f9828accf584"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 915
        },
        "id": "I7nZxE-5jUv_",
        "outputId": "67124903-07be-41f4-ad4b-787b34fbf768"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-34-45c6c61b1a17>\", line 1, in <module>\n",
            "    get_ipython().magic('cd drive/MyDrive')\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2160, in magic\n",
            "    return self.run_line_magic(magic_name, magic_arg_s)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2081, in run_line_magic\n",
            "    result = fn(*args,**kwargs)\n",
            "  File \"<decorator-gen-84>\", line 2, in cd\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\", line 188, in <lambda>\n",
            "    call = lambda f, *a, **k: f(*a, **k)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/magics/osm.py\", line 288, in cd\n",
            "    oldcwd = py3compat.getcwd()\n",
            "FileNotFoundError: [Errno 2] No such file or directory\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'FileNotFoundError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 725, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 709, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.7/posixpath.py\", line 383, in abspath\n",
            "    cwd = os.getcwd()\n",
            "FileNotFoundError: [Errno 2] No such file or directory\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ],
      "source": [
        "cd drive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SpQcMnmsv-s"
      },
      "outputs": [],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNpKcgRupN1x"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "from PIL import Image\n",
        "from collections import OrderedDict\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Import necessary PyTorch libraries\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.models import resnet50\n",
        "from torchvision import datasets, transforms, models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xlXXzHGpT1b"
      },
      "outputs": [],
      "source": [
        "with open(\"test.txt\", \"r\") as f:\n",
        "    test_label = f.read().splitlines()\n",
        "    test_label = [elem[24:] for elem in test_label]\n",
        "    test_label = list(map(int, test_label))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "# generate validate set\n",
        "if not os.path.exists('ImageNet/validate'):\n",
        "    os.mkdir('ImageNet/validate')\n",
        "rootdir = 'ImageNet/train'\n",
        "list=os.listdir(rootdir)\n",
        "for cls in list:\n",
        "    path = os.path.join(rootdir, cls)\n",
        "    des_path = os.path.join('ImageNet/validate', cls)\n",
        "    if not os.path.exists(des_path):\n",
        "        os.mkdir(des_path)\n",
        "    for idx, item in enumerate(os.listdir(path)):\n",
        "        full_path = os.path.join(path, item)\n",
        "        if len(os.listdir(des_path)) < 5:\n",
        "            shutil.move(full_path,des_path)"
      ],
      "metadata": {
        "id": "8z3SOaWFyysq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuTbCJdJpdrI"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, img_path, labels, transform=None):\n",
        "        self.path = img_path\n",
        "        self.data_paths = [f for f in os.listdir(img_path)]\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(os.path.join(self.path,self.data_paths[idx]))\n",
        "        img = img.convert(\"RGB\")\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        \n",
        "        return img, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AZ6l53GpgYX"
      },
      "outputs": [],
      "source": [
        "############## TODO: Data Augumentation ###########################\n",
        "train_transforms = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.RandomVerticalFlip(),\n",
        "                                       transforms.RandomRotation(45),\n",
        "                                       transforms.RandomAffine(45),\n",
        "                                       transforms.ColorJitter(),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                            std=[0.229, 0.224, 0.225])])\n",
        "\n",
        "####################################################################\n",
        "\n",
        "test_transforms = transforms.Compose([transforms.Resize(256),\n",
        "                                      transforms.TenCrop(224),\n",
        "                                      transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
        "                                      transforms.Lambda(lambda crops: torch.stack([transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])(crop) for crop in crops]))])\n",
        "test_transforms_no_crop = transforms.Compose([transforms.Resize((224, 224)),\n",
        "                                transforms.RandomHorizontalFlip(), \n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for ablation study\n",
        "no_crop = True\n",
        "no_dropout = False"
      ],
      "metadata": {
        "id": "ZsevTvSAYQ_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqCjwL3ppiY4"
      },
      "outputs": [],
      "source": [
        "train_dir = 'ImageNet/train'\n",
        "train_data = datasets.ImageFolder(train_dir, train_transforms)\n",
        "\n",
        "val_dir = 'ImageNet/validate'\n",
        "validate_data = datasets.ImageFolder(val_dir, test_transforms)\n",
        "\n",
        "test_dir = 'ImageNet/test'\n",
        "if no_crop:\n",
        "    test_data = CustomDataset(test_dir,test_label,test_transforms_no_crop)\n",
        "else:\n",
        "    test_data = CustomDataset(test_dir,test_label,test_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validate,test = torch.utils.data.random_split(test_data, [5000, 45000])"
      ],
      "metadata": {
        "id": "E-6TTV8TgJqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QB3Ta5bUqWP5"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "dataloaders = {}\n",
        "dataloaders['train'] = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "dataloaders['validate'] = DataLoader(validate, batch_size=batch_size, shuffle=False)\n",
        "dataloaders['test'] = DataLoader(test, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_baseline = False\n",
        "continue_train = True"
      ],
      "metadata": {
        "id": "3tU060GOiJOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = resnet50(pretrained=False)\n",
        "if load_baseline:\n",
        "    checkpoint = torch.load('ImageNet/resnet50_fconv_model_best.pth.tar')\n",
        "    print('Load from baseline')\n",
        "    new_state_dict = OrderedDict()\n",
        "    for k, v in checkpoint['state_dict'].items():\n",
        "        name = k[7:] # remove module.\n",
        "        new_state_dict[name] = v\n",
        "\n",
        "    model.load_state_dict(new_state_dict)\n",
        "    if not no_dropout:\n",
        "        print('dropout')\n",
        "        model.fc = nn.Sequential(nn.BatchNorm1d(2048), nn.Dropout(0.2), nn.Linear(2048, 1000))"
      ],
      "metadata": {
        "id": "kuUAKkleiYIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "metadata": {
        "id": "XI1VP-ZQ_pZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ct = 0\n",
        "for child in model.children():\n",
        "  ct += 1\n",
        "  if ct < 10:\n",
        "      for param in child.parameters():\n",
        "          param.requires_grad = False"
      ],
      "metadata": {
        "id": "trFUKzkw_UkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "metadata": {
        "id": "A51Hrih5_qAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if continue_train:\n",
        "    train_on_gpu = torch.cuda.is_available()\n",
        "    print('Load from checkpoint')\n",
        "    checkpoint = torch.load('ImageNet/res50_model_checkpoint.pth', map_location=torch.device('cuda'))\n",
        "    model = checkpoint['model']\n",
        "    criterion = checkpoint['criterion']\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 5)\n",
        "    n_epochs = 20\n",
        "    valid_loss_min = checkpoint['valid_loss_min'] # track change in validation loss\n",
        "else:\n",
        "    # specify loss function (categorical cross-entropy)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # specify optimizer (stochastic gradient descent with momentum)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "    # secify learning rate scheduler (if there is no further decrease in loss for next 5 epochs \n",
        "    # then lower the learning rate by 0.1)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 5)\n",
        "\n",
        "    train_on_gpu = torch.cuda.is_available()\n",
        "    # Move the model to GPU if CUDA is available\n",
        "    if train_on_gpu:\n",
        "        model.cuda()\n",
        "\n",
        "    # number of epochs to train the model\n",
        "    n_epochs = 20\n",
        "\n",
        "    valid_loss_min = np.Inf # track change in validation loss"
      ],
      "metadata": {
        "id": "Op35Wt2siZxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_error = {}\n",
        "train_acc = {}\n",
        "validate_error = {}\n",
        "validate_acc = {}"
      ],
      "metadata": {
        "id": "7hqJLHL0zndE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(cur_epochs, n_epochs+1):\n",
        "    # keep track of training and validation loss\n",
        "    \n",
        "    train_loss = 0.0\n",
        "    train_accuracy = 0.0\n",
        "    valid_loss = 0.0\n",
        "    val_accuracy = 0.0\n",
        "    \n",
        "\n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    loop = tqdm(enumerate(dataloaders['train']),total=len(dataloaders['train']))\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in loop:\n",
        "        \n",
        "        # move tensors to GPU if CUDA is available\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "        # perform a single optimization step (parameter update)\n",
        "        optimizer.step()\n",
        "        # update training loss\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "        # Calculate training accuracy\n",
        "        top_p, top_class = output.topk(1, dim=1)\n",
        "        equals = top_class == target.view(*top_class.shape)\n",
        "        train_accuracy += torch.mean(equals.type(torch.FloatTensor)).item()*data.size(0)\n",
        "        \n",
        "        loop.set_description(f'train Epoch[{epoch}/{n_epochs}]')\n",
        "        loop.set_postfix(loss=train_loss/len(dataloaders['train'].dataset), acc=train_accuracy/((batch_idx+1)*batch_size))\n",
        "        \n",
        "        \n",
        "        \n",
        "    ######################    \n",
        "    # validate the model #\n",
        "    ######################\n",
        "    loop = tqdm(enumerate(dataloaders['validate']),total=len(dataloaders['validate']),leave=False)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in loop:\n",
        "            # move tensors to GPU if CUDA is available\n",
        "            if train_on_gpu:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "\n",
        "            input_var = torch.autograd.Variable(data, volatile=True)\n",
        "            target_var = torch.autograd.Variable(target, volatile=True)\n",
        "            bs, ncrops, c, h, w = input_var.size()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            temp_output = model(input_var.view(-1, c, h, w))\n",
        "            output = temp_output.view(bs, ncrops, -1).mean(1)\n",
        "            # calculate the batch loss\n",
        "            loss = criterion(output, target_var)\n",
        "            # update average validation loss \n",
        "            valid_loss += loss.item()*data.size(0)\n",
        "            # Calculate validation accuracy\n",
        "            top_p, top_class = output.topk(1, dim=1)\n",
        "            equals = top_class == target.view(*top_class.shape)\n",
        "            val_accuracy += torch.mean(equals.type(torch.FloatTensor)).item()*data.size(0)\n",
        "            \n",
        "            loop.set_description(f'validate Epoch[{epoch}/{n_epochs}]')\n",
        "            loop.set_postfix(loss=valid_loss/len(dataloaders['validate'].dataset), acc=val_accuracy/((batch_idx+1)*batch_size))\n",
        "            \n",
        "    \n",
        "    # calculate average losses and accuracies\n",
        "    train_loss = train_loss/len(dataloaders['train'].dataset)\n",
        "    train_accuracy = train_accuracy/len(dataloaders['train'].dataset)\n",
        "    valid_loss = valid_loss/len(dataloaders['validate'].dataset)\n",
        "    val_accuracy = val_accuracy/len(dataloaders['validate'].dataset)\n",
        "    \n",
        "    train_error[epoch] = train_loss\n",
        "    train_acc[epoch] = train_accuracy\n",
        "    validate_error[epoch] = valid_loss\n",
        "    validate_acc[epoch] = val_accuracy\n",
        "    \n",
        "    # Learning rate scheduler step\n",
        "    scheduler.step(valid_loss) \n",
        "    \n",
        "    # print training/validation statistics \n",
        "    print('Epoch: {} \\tTraining Loss: {:.4f} \\tTraining Accuracy: {:.4f} \\tValidation Loss: {:.4f} \\tValidation Accuracy: {:.4f}'.format(\n",
        "        epoch, train_loss, train_accuracy, valid_loss, val_accuracy))\n",
        "    \n",
        "    # save model if validation loss has decreased\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min, valid_loss))\n",
        "        \n",
        "        checkpoint = {\"model\": model,\n",
        "                      \"criterion\": criterion,\n",
        "                      \"epochs\": epoch,\n",
        "                      \"optimizer_state\": optimizer.state_dict(),\n",
        "                      \"model_state\": model.state_dict(),\n",
        "                      \"valid_loss_min\": valid_loss}\n",
        "    \n",
        "        # save model in colab\n",
        "        torch.save(checkpoint, 'res50_model_checkpoint.pth')\n",
        "        valid_loss_min = valid_loss\n",
        "cur_epochs = n_epochs + 1\n",
        "n_epochs = n_epochs + 20"
      ],
      "metadata": {
        "id": "ggEahtOriqvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = 0.0\n",
        "test_accuracy = 0.0\n",
        "loop = tqdm(enumerate(dataloaders['test']),total=len(dataloaders['test']),leave=False)\n",
        "model.eval()\n",
        "top_class_overall = []\n",
        "equals_overall = []\n",
        "targets = []\n",
        "with torch.no_grad():\n",
        "    for batch_idx, (data, target) in loop:\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "\n",
        "        input_var = torch.autograd.Variable(data, volatile=True)\n",
        "        target_var = torch.autograd.Variable(target, volatile=True)\n",
        "        bs, ncrops, c, h, w = input_var.size()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        temp_output = model(input_var.view(-1, c, h, w))\n",
        "        output = temp_output.view(bs, ncrops, -1).mean(1)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target_var)\n",
        "        # update average validation loss \n",
        "        test_loss += loss.item()*data.size(0)\n",
        "        # Calculate validation accuracy\n",
        "        top_p, top_class = output.topk(1, dim=1)\n",
        "        equals = top_class == target.view(*top_class.shape)\n",
        "        test_accuracy += torch.mean(equals.type(torch.FloatTensor)).item()*data.size(0)\n",
        "\n",
        "        targets += target.cpu().numpy().tolist()\n",
        "        top_class_overall += top_class.cpu().numpy().tolist()\n",
        "        equals_overall += equals.cpu().numpy().tolist()\n",
        "\n",
        "        loop.set_description(f'test Epoch[{epoch}/{n_epochs}]')\n",
        "        loop.set_postfix(loss=test_loss/len(dataloaders['test'].dataset), acc=test_accuracy/((batch_idx+1)*batch_size))\n",
        "test_loss = test_loss/len(dataloaders['test'].dataset)\n",
        "test_accuracy = test_accuracy/len(dataloaders['test'].dataset)"
      ],
      "metadata": {
        "id": "nQUVayIrzqlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('train_error', train_error)\n",
        "np.save('train_acc', train_acc)\n",
        "np.save('validate_error', validate_error)\n",
        "np.save('validate_acc', validate_acc)"
      ],
      "metadata": {
        "id": "ovIXGdM5zwjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_error = np.load('save/train_error.npy', allow_pickle=True).item()\n",
        "train_acc = np.load('save/train_acc.npy', allow_pickle=True).item()\n",
        "validate_error = np.load('save/validate_error.npy', allow_pickle=True).item()\n",
        "validate_acc = np.load('save/validate_acc.npy', allow_pickle=True).item()\n",
        "test_acc = {}\n",
        "test_loss = {}\n",
        "test_acc[20] = np.load('save/test_accuracy_20.npy', allow_pickle=True).item()\n",
        "test_acc[40] = np.load('save/test_accuracy_40.npy', allow_pickle=True).item()\n",
        "test_acc[60] = np.load('save/test_accuracy_60.npy', allow_pickle=True).item()\n",
        "test_acc[80] = np.load('save/test_accuracy_80.npy', allow_pickle=True).item()\n",
        "test_loss[20] = np.load('save/test_loss_20.npy', allow_pickle=True).item()\n",
        "test_loss[40] = np.load('save/test_loss_40.npy', allow_pickle=True).item()\n",
        "test_loss[60] = np.load('save/test_loss_60.npy', allow_pickle=True).item()\n",
        "test_loss[80] = np.load('save/test_loss_80.npy', allow_pickle=True).item()"
      ],
      "metadata": {
        "id": "rVO15Q0KYp34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "with PdfPages('train.pdf') as pdf:\n",
        "    fig_1 = plt.figure(figsize=(8, 8))\n",
        "    ax_1 = fig_1.add_subplot(211)\n",
        "    ax_1.plot(train_error.keys(), train_error.values(), label='train error',linestyle='--')\n",
        "    ax_1.plot(validate_error.keys(), validate_error.values(), label='validate error',linestyle='--')\n",
        "    ax_1.legend(loc=0)\n",
        "    ax_1.set_xlabel('Epoch number')\n",
        "    ax_1.set_ylabel('Error')\n",
        "    ax_1.set_title('Train and validate error and acc')\n",
        "    ax_2 = fig_1.add_subplot(212)\n",
        "    ax_2.plot(train_acc.keys(), train_acc.values(), label='train accuracy',linestyle='--')\n",
        "    ax_2.plot(validate_acc.keys(), validate_acc.values(), label='validate accuracy',linestyle='--')\n",
        "    ax_2.legend(loc=0)\n",
        "    ax_2.set_xlabel('Epoch number')\n",
        "    ax_2.set_ylabel('Accuracy')\n",
        "    pdf.savefig(fig_1)\n",
        "with PdfPages('test.pdf') as pdf:\n",
        "    fig_2 = plt.figure(figsize=(8, 8))\n",
        "    ax_3 = fig_2.add_subplot(211)\n",
        "    ax_3.scatter(test_loss.keys(), test_loss.values(), label='test error')\n",
        "    ax_3.plot(test_loss.keys(), test_loss.values(), linestyle='--')\n",
        "    ax_3.legend(loc=0)\n",
        "    ax_3.set_xlabel('Epoch number')\n",
        "    ax_3.set_ylabel('Error')\n",
        "    ax_3.set_title('Test error and acc')\n",
        "    ax_4 = fig_2.add_subplot(212)\n",
        "    ax_4.scatter(test_acc.keys(), test_acc.values(), label='test accuracy')\n",
        "    ax_4.plot(test_acc.keys(), test_acc.values(), linestyle='--')\n",
        "    ax_4.legend(loc=0)\n",
        "    ax_4.set_xlabel('Epoch number')\n",
        "    ax_4.set_ylabel('Accuracy')\n",
        "    pdf.savefig(fig_2)"
      ],
      "metadata": {
        "id": "q-rlgCOWYw4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ablation study\n",
        "def test(no_crop, dataloaders, model):\n",
        "    loss = 0.0\n",
        "    accuracy = 0.0\n",
        "    loop = tqdm(enumerate(dataloaders['test']),total=len(dataloaders['test']),leave=False)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in loop:\n",
        "            # move tensors to GPU if CUDA is available\n",
        "            if train_on_gpu:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            if not no_crop:\n",
        "                input_var = torch.autograd.Variable(data, volatile=True)\n",
        "                target_var = torch.autograd.Variable(target, volatile=True)\n",
        "                bs, ncrops, c, h, w = input_var.size()\n",
        "                # forward pass: compute predicted outputs by passing inputs to the model\n",
        "                temp_output = model(input_var.view(-1, c, h, w))\n",
        "                output = temp_output.view(bs, ncrops, -1).mean(1)\n",
        "                # calculate the batch loss\n",
        "                loss = criterion(output, target_var)\n",
        "            else:\n",
        "                output = model(data)\n",
        "                # calculate the batch loss\n",
        "                loss = criterion(output, target)\n",
        "                \n",
        "            # update average validation loss \n",
        "            loss += loss.item()*data.size(0)\n",
        "            # Calculate validation accuracy\n",
        "            top_p, top_class = output.topk(1, dim=1)\n",
        "            equals = top_class == target.view(*top_class.shape)\n",
        "            accuracy += torch.mean(equals.type(torch.FloatTensor)).item()*data.size(0)\n",
        "            loop.set_description(f'test Epoch[{epoch}/{n_epochs}]')\n",
        "            loop.set_postfix(loss=loss/len(dataloaders['test'].dataset), acc=accuracy/((batch_idx+1)*batch_size))\n",
        "\n",
        "\n",
        "    loss = loss/len(dataloaders['test'].dataset)\n",
        "    accuracy = accuracy/len(dataloaders['test'].dataset)\n",
        "    return loss, accuracy"
      ],
      "metadata": {
        "id": "GnZ8PK0CYjzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#no dropout\n",
        "test_loss_no_dropout, test_accuracy_no_dropout = test(no_crop, dataloaders, model)\n",
        "np.save('test_loss_no_dropout',test_loss_no_dropout)\n",
        "np.save('test_accuracy_no_dropout',test_accuracy_no_dropout)\n",
        "print('test_loss_no_dropout:',test_loss_no_dropout)\n",
        "print('test_accuracy_no_dropout:',test_accuracy_no_dropout)"
      ],
      "metadata": {
        "id": "tuBoh_DMYh47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#no crop\n",
        "test_loss_no_crop, test_accuracy_no_crop = test(no_crop, dataloaders, model)\n",
        "np.save('test_loss_no_crop',test_loss_no_crop)\n",
        "np.save('test_accuracy_no_crop',test_accuracy_no_crop)\n",
        "print('test_loss_no_crop:',test_loss_no_crop)\n",
        "print('test_accuracy_no_crop:',test_accuracy_no_crop)"
      ],
      "metadata": {
        "id": "yM_Z6jvNYnOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#no crop no dropout\n",
        "test_loss_no_crop_no_dropout, test_accuracy_no_crop_no_dropout = test(no_crop, dataloaders, model)\n",
        "np.save('test_loss_no_crop_no_dropout',test_loss_no_crop_no_dropout)\n",
        "np.save('test_accuracy_no_crop_no_dropout',test_accuracy_no_crop_no_dropout)\n",
        "print('test_loss_no_crop_no_dropout:',test_loss_no_crop_no_dropout)\n",
        "print('test_accuracy_no_crop_no_dropout:',test_accuracy_no_crop_no_dropout)"
      ],
      "metadata": {
        "id": "vVYpRMmJYpRe"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "machine_shape": "hm",
      "name": "Resnet50.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}